{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":456741,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":370367,"modelId":391263},{"sourceId":456954,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":370529,"modelId":391429},{"sourceId":460150,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":372692,"modelId":393551},{"sourceId":460160,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":372698,"modelId":393556},{"sourceId":460255,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":372763,"modelId":393619},{"sourceId":460263,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":372767,"modelId":393623}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Final\n\nNotebook, en el que se usan todos los modelos","metadata":{}},{"cell_type":"code","source":"!pip install bertopic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:45:47.562368Z","iopub.execute_input":"2025-07-13T09:45:47.562588Z","iopub.status.idle":"2025-07-13T09:47:12.983827Z","shell.execute_reply.started":"2025-07-13T09:45:47.562568Z","shell.execute_reply":"2025-07-13T09:47:12.982055Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting bertopic\n  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.8.40)\nRequirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.5.7)\nRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.26.4)\nRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.3)\nRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\nRequirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (1.2.2)\nRequirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (3.4.1)\nRequirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.11/dist-packages (from bertopic) (4.67.1)\nRequirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.43.0)\nRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.15.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan>=0.8.29->bertopic) (1.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->bertopic) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->bertopic) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->bertopic) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->bertopic) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->bertopic) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20.0->bertopic) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (9.1.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (25.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.51.3)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.6.0+cu124)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.31.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.4.1->bertopic) (11.1.0)\nRequirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\nRequirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.3.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (1.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.5.3)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20.0->bertopic) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20.0->bertopic) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20.0->bertopic) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20.0->bertopic) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20.0->bertopic) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.4.26)\nDownloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bertopic\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed bertopic-0.17.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import joblib\n\nimport torch\n\nfrom bertopic import BERTopic\nfrom sentence_transformers import SentenceTransformer\n\nfrom gensim.models import LdaModel\nfrom gensim.corpora import Dictionary\nfrom gensim.utils import simple_preprocess\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\nfrom transformers import BertForSequenceClassification, BertTokenizer\n\nclass Models:\n\n    def __init__(self):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        \n        self.bert_topic_model = BERTopic.load(\"/kaggle/input/bertopic/transformers/default/1/modelo_bertopic\",\n        embedding_model=\"all-MiniLM-L6-v2\" )\n\n        self.lda_model = LdaModel.load(\"/kaggle/input/topic_modeling_lda/other/default/1/topic_modeling_lda/model/lda_model_gensim.model\")\n        self.lda_dictionary = Dictionary.load(\"/kaggle/input/topic_modeling_lda/other/default/1/topic_modeling_lda/dic/diccionario.dict\")\n        \n        self.svm_sentiment_model = joblib.load(\"/kaggle/input/ml_sentiment/scikitlearn/default/1/bert_sentiment_model/svm/svm.joblib\")\n        self.knn_sentiment_model = joblib.load(\"/kaggle/input/ml_sentiment/scikitlearn/default/1/bert_sentiment_model/knn/knn.joblib\")\n        self.lr_sentiment_model = joblib.load(\"/kaggle/input/ml_sentiment/scikitlearn/default/1/bert_sentiment_model/lr/lr.joblib\")\n        self.nb_sentiment_model = joblib.load(\"/kaggle/input/ml_sentiment/scikitlearn/default/1/bert_sentiment_model/nb/nb.joblib\")\n        self.rf_sentiment_model = joblib.load(\"/kaggle/input/ml_sentiment/scikitlearn/default/1/bert_sentiment_model/rf/rf.joblib\")\n\n        self.bert_sentiment_tokenizer = BertTokenizer.from_pretrained(\"/kaggle/input/bert_sentiment/transformers/default/1/bert_sentiment_model/tokenizer/bert_tokenizer\")\n        self.bert_sentiment_model = BertForSequenceClassification.from_pretrained(\"/kaggle/input/bert_sentiment/transformers/default/1/bert_sentiment_model/model/bert_sentiment_model\")\n        self.id2label_sentiment = {0: \"Negativo\", 1: \"Neutro\", 2: \"Positivo\"}\n\n        self.bert_fake_news_tokenizer = BertTokenizer.from_pretrained(\"/kaggle/input/bert_fake/transformers/default/1/bert_fake_news/tokenizer/bert_tokenizer\")\n        self.bert_fake_news_model = BertForSequenceClassification.from_pretrained(\"/kaggle/input/bert_fake/transformers/default/1/bert_fake_news/model/bert_fake_news_model\")\n        self.id2label_fake_news = {0: \"Falso\", 1: \"Real\"}\n\n        self.svm_fake_news_model = joblib.load(\"/kaggle/input/ml_fake/scikitlearn/default/1/ml_fake_news/svm/svm.joblib\")\n        self.knn_fake_news_model = joblib.load(\"/kaggle/input/ml_fake/scikitlearn/default/1/ml_fake_news/knn/knn.joblib\")\n        self.lr_fake_news_model = joblib.load(\"/kaggle/input/ml_fake/scikitlearn/default/1/ml_fake_news/lr/lr.joblib\")\n        self.nb_fake_news_model = joblib.load(\"/kaggle/input/ml_fake/scikitlearn/default/1/ml_fake_news/nb/nb.joblib\")\n        self.rf_fake_news_model = joblib.load(\"/kaggle/input/ml_fake/scikitlearn/default/1/ml_fake_news/rf/rf.joblib\")\n\n    \n    def predict_bert_topic(self,doc):\n        topic, probs = self.bert_topic_model.transform(doc)\n        print(probs)\n        if topic != -1:  \n            tema = self.bert_topic_model.get_topic(topic[0])  \n            palabras = [palabra for palabra, _ in tema]\n            print(f\"Documento: {doc}\\n→ Tópico {topic[0]}: {', '.join(palabras[:10])}\\n\")\n        else:\n            print(f\"Documento: {doc}\\n→ Tópico: No asignado\\n\")\n                \n    def __get_topics_lda(self,num_words=10):\n        topic_labels = {}\n        num_topics = self.lda_model.num_topics\n        topics = self.lda_model.show_topics(num_topics=num_topics, formatted=False, num_words=num_words)\n        for topic_id, words in topics:\n            label = \", \".join([word for word, _ in words])\n            topic_labels[topic_id] = label\n        return topic_labels\n\n    def __preprocess_lda(self,docs):\n        return [word for word in simple_preprocess(docs) if word not in stop_words]\n\n    def __predict_topic_with_label(self,text, topic_labels):\n        bow = self.lda_dictionary.doc2bow(self.__preprocess_lda(text))\n        topic_dist = self.lda_model.get_document_topics(bow)\n        if not topic_dist:\n            return None, None\n        main_topic_id = sorted(topic_dist, key=lambda x: -x[1])[0][0]\n        return main_topic_id, topic_labels.get(main_topic_id, \"Tema desconocido\")\n\n    def predict_lda_topic(self, texto):\n        topic_labels = self.__get_topics_lda()\n        \n        topic_id, topic_name = self.__predict_topic_with_label(texto, topic_labels)\n        \n        print(f\"Tema predicho: {topic_id} - {topic_name}\")\n\n    def __predict_bert(self, texto, model, tokenizer, max_lenght, id2label):\n        inputs = tokenizer(\n                texto,\n                add_special_tokens=True,\n                max_length=max_lenght,\n                padding='max_length',\n                truncation=True,\n                return_tensors='pt'\n            )\n    \n        # Mover los tensores al dispositivo (CPU o GPU)\n        input_ids = inputs[\"input_ids\"].to(self.device)\n        attention_mask = inputs[\"attention_mask\"].to(self.device)\n    \n        # Desactivar gradientes para inferencia\n        with torch.no_grad():\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            pred_id = torch.argmax(logits, dim=1).item()\n    \n        return id2label[pred_id]\n        #return pred_id\n\n    def predict_bert_sentiment(self, text):\n        return self.__predict_bert(text, self.bert_sentiment_model, self.bert_sentiment_tokenizer, 128,self.id2label_sentiment)\n\n    def predict_ml_sentiment(self, text, slc_model = 'svm'):\n        if(slc_model == 'svm'):\n            pred = self.id2label_sentiment[self.svm_sentiment_model.predict([text])[0]]\n        elif(slc_model == 'knn'):\n            pred = self.id2label_sentiment[self.knn_sentiment_model.predict([text])[0]]\n        elif(slc_model == 'lr'):\n            pred = self.id2label_sentiment[self.lr_sentiment_model.predict([text])[0]]\n        elif(slc_model == 'nb'):\n            pred = self.id2label_sentiment[self.nb_sentiment_model.predict([text])[0]]\n        elif(slc_model == 'rf'):\n            pred = self.id2label_sentiment[self.rf_sentiment_model.predict([text])[0]]\n        return pred\n\n    def predict_bert_fake_news(self, text):\n        return self.__predict_bert(text, self.bert_fake_news_model, self.bert_fake_news_tokenizer, 512,self.id2label_fake_news)\n\n    def predict_ml_fake_news(self, text, slc_model = 'svm'):\n        if(slc_model == 'svm'):\n            pred = self.id2label_fake_news[self.svm_fake_news_model.predict([text])[0]]\n        elif(slc_model == 'knn'):\n            pred = self.id2label_fake_news[self.knn_fake_news_model.predict([text])[0]]\n        elif(slc_model == 'lr'):\n            pred = self.id2label_fake_news[self.lr_fake_news_model.predict([text])[0]]\n        elif(slc_model == 'nb'):\n            pred = self.id2label_fake_news[self.nb_fake_news_model.predict([text])[0]]\n        elif(slc_model == 'rf'):\n            pred = self.id2label_fake_news[self.rf_fake_news_model.predict([text])[0]]\n        return pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:47:40.622103Z","iopub.execute_input":"2025-07-13T09:47:40.622516Z","iopub.status.idle":"2025-07-13T09:50:37.134042Z","shell.execute_reply.started":"2025-07-13T09:47:40.622462Z","shell.execute_reply":"2025-07-13T09:50:37.133297Z"}},"outputs":[{"name":"stderr","text":"2025-07-13 09:48:09.541196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752400089.767598      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752400089.834385      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import time\n\nmodel = Models()\n\nstart = time.time()\n\ntexto = \"A controversial new study published by the non-peer-reviewed journal Global Wellness Watch claims that major coffee brands have been embedding microscopic tracking chips inside coffee beans since 2021. The alleged goal: to monitor consumer drinking habits and location data in real time.\"\n\nmodel.predict_bert_topic(texto)\nend = time.time()\n\nelapsed_ms = (end - start) * 1000  # convertir a milisegundos\nprint(f\"Tiempo transcurrido: {elapsed_ms:.2f} ms\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T09:53:08.121175Z","iopub.execute_input":"2025-07-13T09:53:08.121904Z","iopub.status.idle":"2025-07-13T09:53:12.502296Z","shell.execute_reply.started":"2025-07-13T09:53:08.121874Z","shell.execute_reply":"2025-07-13T09:53:12.501502Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11c520ad58e4a1ba31905cefdbb68dd"}},"metadata":{}},{"name":"stderr","text":"2025-07-13 09:53:12,485 - BERTopic - Dimensionality - Reducing dimensionality of input embeddings.\n2025-07-13 09:53:12,495 - BERTopic - Dimensionality - Completed ✓\n2025-07-13 09:53:12,496 - BERTopic - Clustering - Approximating new points with `hdbscan_model`\n2025-07-13 09:53:12,498 - BERTopic - Cluster - Completed ✓\n","output_type":"stream"},{"name":"stdout","text":"[0.89869101]\nDocumento: A controversial new study published by the non-peer-reviewed journal Global Wellness Watch claims that major coffee brands have been embedding microscopic tracking chips inside coffee beans since 2021. The alleged goal: to monitor consumer drinking habits and location data in real time.\n→ Tópico 33: coffee, tea, starbucks, cup, espresso, iced, cups, good, having, baristas\n\nTiempo transcurrido: 57.63 ms\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"","metadata":{}}]}